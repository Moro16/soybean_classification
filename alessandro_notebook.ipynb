{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a73bdd-c14f-48cc-a6f4-cdd061fddc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "# path = kagglehub.dataset_download(\"warcoder/soyabean-seeds\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f3ab27-7850-41e5-bc97-a7a46a6f660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"raw_data/Soybean Seeds\"\n",
    "train_path = \"raw_data/train\"\n",
    "val_path = \"raw_data/val\"\n",
    "test_path = \"raw_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa86aed-1378-47f2-a802-12c2f6c57297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9c6cbd-8054-4e14-8ef9-174e4caaca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe61a857-e6da-4243-ad87-a81ee9538e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_ratio = 0.7\n",
    "# val_ratio = .15\n",
    "\n",
    "# for class_folder in os.listdir(dataset_path):\n",
    "#     class_path = os.path.join(dataset_path, class_folder)\n",
    "#     images = os.listdir(class_path)\n",
    "#     random.shuffle(images)\n",
    "\n",
    "#     # Calculate the split index\n",
    "#     split_index = int(train_ratio * len(images))\n",
    "#     val_len = int(len(images) * (1-val_ratio))\n",
    "\n",
    "#     # Split the images into training and testing sets\n",
    "#     train_images = images[:split_index]\n",
    "#     val_images = images[split_index:val_len]\n",
    "#     test_images = images[val_len:]\n",
    "\n",
    "#     # Create class folders in the training and testing directories\n",
    "#     train_class_path = os.path.join(train_path, class_folder)\n",
    "#     val_class_path = os.path.join(val_path, class_folder)\n",
    "#     test_class_path = os.path.join(test_path, class_folder)\n",
    "#     os.makedirs(train_class_path, exist_ok=True)\n",
    "#     os.makedirs(val_class_path, exist_ok=True)\n",
    "#     os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "#     # Move images to the respective class folders in training and testing\n",
    "#     for image in train_images:\n",
    "#         src = os.path.join(class_path, image)\n",
    "#         dest = os.path.join(train_class_path, image)\n",
    "#         shutil.copy(src, dest)\n",
    "\n",
    "#     for image in val_images:\n",
    "#         src = os.path.join(class_path, image)\n",
    "#         dest = os.path.join(val_class_path, image)\n",
    "#         shutil.copy(src, dest)\n",
    "\n",
    "#     for image in test_images:\n",
    "#         src = os.path.join(class_path, image)\n",
    "#         dest = os.path.join(test_class_path, image)\n",
    "#         shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88a4948-3ec5-47e4-865d-4a628b3662fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 14:28:50.604146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-30 14:28:50.604209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-30 14:28:50.608311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-30 14:28:50.625157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-30 14:28:51.572804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-30 14:28:52.333272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-30 14:28:52.408350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-30 14:28:52.408402: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,Activation,Dropout,MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8e41e0-e2f0-4af8-bbd7-3a049bd49e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = load_img(f'{train_path}/Broken soybeans/3.jpg')\n",
    "# x = img_to_array(img)/255\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c586fb0d-eac8-4241-b3c0-948425c1fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a69776-a113-4e75-846a-99958a9bdab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"raw_data/train\"\n",
    "val_dir = \"raw_data/test\"\n",
    "test_dir = \"raw_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449e5385-0f1e-4c55-ba56-0da0f3afac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=[\"path\", \"class\"])\n",
    "val_df = pd.DataFrame(columns=[\"path\", \"class\"])\n",
    "test_df = pd.DataFrame(columns=[\"path\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5678bc-9cc8-4e45-bba9-20df164b605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class_name in os.listdir(train_dir):\n",
    "#   class_dir = os.path.join(train_dir, class_name)\n",
    "#   for image_name in os.listdir(class_dir):\n",
    "#     image_path = os.path.join(class_dir, image_name)\n",
    "#     train_df.loc[len(train_df.index)] = [image_path, class_name]\n",
    "\n",
    "# for class_name in os.listdir(test_dir):\n",
    "#   class_dir = os.path.join(test_dir, class_name)\n",
    "#   for image_name in os.listdir(class_dir):\n",
    "#     image_path = os.path.join(class_dir, image_name)\n",
    "#     test_df.loc[len(test_df.index)] = [image_path, class_name]\n",
    "\n",
    "# for class_name in os.listdir(val_dir):\n",
    "#   class_dir = os.path.join(val_dir, class_name)\n",
    "#   for image_name in os.listdir(class_dir):\n",
    "#     image_path = os.path.join(class_dir, image_name)\n",
    "#     val_df.loc[len(val_df.index)] = [image_path, class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df8bcb3-76c8-4fa0-ab0a-973d267272d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_df.info(), val_df.info(), test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c0126a-2dab-4b14-9252-b3932dfef294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4fcc849-b8e7-443f-af44-63b9ecc83994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('accuracy')\n",
    "    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff5bdc4-d3e3-4a29-9caa-b43b53a3e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_compare_history(history, name_history, history_1, name_history_1):\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "#     ax[0].set_title('loss')\n",
    "\n",
    "#     ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss \" + name_history)\n",
    "#     ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss \" + name_history)\n",
    "\n",
    "#     ax[0].plot(history_1.epoch, history_1.history[\"loss\"], label=\"Train loss \" + name_history_1)\n",
    "#     ax[0].plot(history_1.epoch, history_1.history[\"val_loss\"], label=\"Validation loss \" + name_history_1)\n",
    "\n",
    "#     ax[1].set_title('Accuracy')\n",
    "\n",
    "#     ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train Accuracy \" + name_history)\n",
    "#     ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation Accuracy \" + name_history)\n",
    "\n",
    "#     ax[1].plot(history_1.epoch, history_1.history[\"accuracy\"], label=\"Train Accuracy \" + name_history_1)\n",
    "#     ax[1].plot(history_1.epoch, history_1.history[\"val_accuracy\"], label=\"Validation Accuracy \" + name_history_1)\n",
    "\n",
    "#     ax[0].legend()\n",
    "#     ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4da00-6cdb-46ca-b744-ffa966459ad7",
   "metadata": {},
   "source": [
    "# PRIMEIRO MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7916e01f-7833-4291-976b-40b223a51839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(layers.Rescaling(1/255, input_shape=(227,227,3)))\n",
    "\n",
    "# model.add(layers.RandomFlip(mode='horizontal_and_vertical'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(5,5), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(3,3), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(96, activation='relu'))\n",
    "# model.add(layers.Dropout(.5))\n",
    "\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dropout(.5))\n",
    "\n",
    "# model.add(layers.Dense(5,activation=\"softmax\"))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b95585-b8fa-488a-8fdf-be4668386ba1",
   "metadata": {},
   "source": [
    "# MODELO MELHORADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6c60c-ebe3-453d-8206-98f240137bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Rescaling(1/255, input_shape=(128,128,3)))\n",
    "\n",
    "model.add(layers.RandomFlip(mode='horizontal'))\n",
    "model.add(layers.RandomFlip(mode='vertical'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(3,3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(4,4), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(.4))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(.4))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(.4))\n",
    "\n",
    "model.add(layers.Dense(5,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ab3ae-b7da-4031-96ec-eb91b6f8719c",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae9d32-c9d5-4053-b74c-59956dfaebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(layers.Rescaling(1/255, input_shape=(227,227,3)))\n",
    "\n",
    "# model.add(layers.RandomFlip(mode='horizontal_and_vertical'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(5,activation=\"softmax\"))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02eff52-d476-4fe2-bb67-ef44e9abdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dense,Flatten,Conv2D,Activation,Dropout,MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81e9f7-98c5-4e5a-9ca5-da27cf5ae6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(input_shape=(227,227,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "# model.add(Flatten(name='flatten'))\n",
    "# model.add(Dense(256, activation='relu', name='fc1'))\n",
    "# model.add(Dense(128, activation='relu', name='fc2'))\n",
    "# model.add(Dense(5, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c60887-6f47-4a6e-b83c-ecfe5e4f7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = optimizers.SGD(learning_rate=1e-6, momentum=0.9)\n",
    "# model.compile(loss=\"categorical_crossentropy\",\n",
    "#               optimizer=opt,\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a427731-441a-4394-aabf-ae312f718cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate = .001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=adam,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c739cd-7971-470c-a15a-94f1c8fe40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'categorical',\n",
    "    class_names = ['Broken soybeans', 'Immature soybeans', 'Intact soybeans', 'Skin-damaged soybeans', 'Spotted soybeans'],\n",
    "    image_size=(128,128),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode = 'categorical',\n",
    "    class_names = ['Broken soybeans', 'Immature soybeans', 'Intact soybeans', 'Skin-damaged soybeans', 'Spotted soybeans'],\n",
    "    image_size=(128,128),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode = 'categorical',\n",
    "    class_names = ['Broken soybeans', 'Immature soybeans', 'Intact soybeans', 'Skin-damaged soybeans', 'Spotted soybeans'],\n",
    "    image_size=(128,128),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d5a75-683c-40da-a8bd-a101214c8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = train_ds.class_names\n",
    "# print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd2244-40be-41d3-b82a-883289e78e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"model_1.keras\"\n",
    "\n",
    "modelCheckpoint = callbacks.ModelCheckpoint(MODEL,\n",
    "                                            monitor=\"val_accuracy\",\n",
    "                                            verbose=0,\n",
    "                                            save_best_only=True)\n",
    "\n",
    "LRreducer = callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
    "                                        factor=0.1,\n",
    "                                        patience=5,\n",
    "                                        verbose=1,\n",
    "                                        min_lr=0)\n",
    "\n",
    "EarlyStopper = callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                       patience=15,\n",
    "                                       verbose=0,\n",
    "                                       restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262cf2f-3a2a-41d0-8e6d-d442bc30da8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=900,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[modelCheckpoint, LRreducer, EarlyStopper]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e5ba9-0124-4de9-908f-d6d679ab5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb5e47-611a-42b7-b80c-bddc6eb7c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0c6fb-7b24-4be5-bb0e-6921207eeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_val_loss:0.3586-val_accuracy:0.9048\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70670126-07e7-4e57-8ccf-e627c75ebf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_90 = load_model(\"model_val_loss:0.3586-val_accuracy:0.9048\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fd37a-e163-4a28-b7cd-cedcbfabc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_90.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc54b2-227a-473f-8aa7-d54534657767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_90.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7586f-4a2c-46e2-9262-7b665ed4773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(f'{test_path}/Broken soybeans/63.jpg', target_size=(128,128))\n",
    "img_array = img_to_array(img)\n",
    "x = np.expand_dims(img_array, axis=0)\n",
    "pred = model_90.predict(x)\n",
    "numero_classe = list(pred[0]).index(pred.max())\n",
    "classe_lista = ['Broken soybeans', 'Immature soybeans', 'Intact soybeans', 'Skin-damaged soybeans', 'Spotted soybeans']\n",
    "pred, classe_lista[numero_classe],round(pred.max()*100, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
